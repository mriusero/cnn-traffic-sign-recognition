{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d920b1",
   "metadata": {},
   "source": [
    "# projet-sda-deep-learning\n",
    "#### [GTSRB - German Traffic Sign Recognition Benchmark](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45c3d48c7f38f2",
   "metadata": {},
   "source": [
    "## 1. **Introduction au Projet**\n",
    "  - Analyse du problème de classification des panneaux de signalisation routière.\n",
    "  - Importance de cette tâche dans les systèmes de conduite autonome.\n",
    "  - Présentation du dataset GTSRB (German Traffic Sign Recognition Benchmark).\n",
    "  - Objectifs du projet.\n",
    "\n",
    "## ToDo\n",
    "- [ ] Importation des library \n",
    "- [ ] Chargement du dataset GTSRB.\n",
    "- [ ] Aperçu des classes de panneaux de signalisation présentes dans le dataset (visualisation des premières images et des labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9188055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d048a890a1448501",
   "metadata": {},
   "source": [
    "## 2. **Préparation des Données**\n",
    "  - Explication des étapes de prétraitement des données.\n",
    "  - Importance du redimensionnement, de la normalisation et de l’augmentation des données.\n",
    "\n",
    "## ToDo\n",
    "- [ ] Chargement et exploration du dataset\n",
    "  - [ ] Dimensions\n",
    "  - [ ] Classes\n",
    "  - [ ] Visualisation des images\n",
    "  - [ ] Distribution des classes\n",
    "- [ ] Prétraitement des images\n",
    "  - [ ] Redimensionnement à une taille fixe (par exemple, 32x32 ou 64x64)\n",
    "  - [ ] Normalisation des valeurs des pixels (mise à l’échelle entre 0 et 1)\n",
    "- [ ] Division du dataset en ensembles d’entraînement, de validation et de test\n",
    "  - [ ] Utilisation de `train_test_split` ou autre technique de séparation\n",
    "- [ ] Implémentation de l’augmentation des données\n",
    "  - [ ] Rotation\n",
    "  - [ ] Zoom\n",
    "  - [ ] Translation\n",
    "  - [ ] Variations de luminosité\n",
    "  - [ ] Via des bibliothèques comme `ImageDataGenerator` ou `torchvision.transforms`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ffeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d05ec331500e229",
   "metadata": {},
   "source": [
    "## 3. **Conception et Implémentation du Modèle CNN**\n",
    "  - Présentation des concepts de base des CNN (convolutions, pooling, fully connected layers).\n",
    "  - Comparaison d’architectures : du simple au complexe (VGG, ResNet).\n",
    "  - Techniques de régularisation (Dropout, Batch Normalization).\n",
    "\n",
    "## ToDo\n",
    "- [ ] Implémentation d’une architecture CNN simple\n",
    "  - [ ] Couches de convolution\n",
    "  - [ ] Couches de pooling\n",
    "  - [ ] Couches fully connected\n",
    "- [ ] Ajout de techniques de régularisation\n",
    "  - [ ] Dropout pour prévenir l’overfitting\n",
    "  - [ ] Batch Normalization pour stabiliser et accélérer l'entraînement\n",
    "- [ ] Exploration d’architectures plus complexes\n",
    "  - [ ] Par exemple, VGG16 ou ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02b2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9d54c5",
   "metadata": {},
   "source": [
    "## 4. **Entraînement du Modèle**\n",
    "  - Définir les paramètres d’entraînement (fonction de coût, optimiseur).\n",
    "  - Importance du suivi des performances sur l’ensemble de validation.\n",
    "\n",
    "## ToDo\n",
    "- [ ] Choix de la fonction de coût\n",
    "  - [ ] `categorical_crossentropy` pour la classification multi-classes\n",
    "- [ ] Implémentation des optimisateurs\n",
    "  - [ ] Adam\n",
    "  - [ ] SGD (avec annealing du taux d’apprentissage)\n",
    "- [ ] Entraînement du modèle sur les données prétraitées et augmentées\n",
    "  - [ ] Suivi des performances sur l’ensemble de validation\n",
    "- [ ] Visualisation des courbes de loss et d’accuracy pendant l’entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38347ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb66bb8c",
   "metadata": {},
   "source": [
    "## 5. **Évaluation du Modèle**\n",
    "  - Explication des métriques de performance : précision, rappel, F1-score.\n",
    "  - Importance de la matrice de confusion pour comprendre les erreurs de classification.\n",
    "\n",
    "## ToDo\n",
    "- [ ] Évaluation du modèle sur l’ensemble de test\n",
    "- [ ] Calcul et affichage des métriques de performance\n",
    "  - [ ] Précision\n",
    "  - [ ] Rappel\n",
    "  - [ ] F1-score\n",
    "- [ ] Génération et visualisation d’une matrice de confusion\n",
    "- [ ] Optionnel : comparer les performances des différentes architectures testées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d67e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e34d8b14",
   "metadata": {},
   "source": [
    "## 6. **Améliorations et Expérimentations**\n",
    "  - Amélioration des performances (ajustement des hyperparamètres, augmentation des données, transfer learning).\n",
    "  - Techniques avancées : le transfer learning.\n",
    "\n",
    "## ToDo \n",
    "- [ ] Ajustement des hyperparamètres\n",
    "  - [ ] Taille des batchs\n",
    "  - [ ] Taux d’apprentissage\n",
    "- [ ] Test d’autres techniques d’augmentation des données\n",
    "- [ ] Implémentation du transfer learning avec un modèle pré-entraîné\n",
    "  - [ ] Par exemple, ResNet ou VGG pré-entraîné sur ImageNet\n",
    "- [ ] Fine-tuning du modèle pré-entraîné sur le dataset GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d902179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9531aab",
   "metadata": {},
   "source": [
    "## 7. **Interprétation et Visualisation des Résultats**\n",
    "  - Explication de l’importance de visualiser les activations des couches CNN.\n",
    "  - Présentation de Grad-CAM pour l’interprétation des résultats.\n",
    "\n",
    "## ToDo\n",
    "- [ ] Visualisation des activations des différentes couches du modèle\n",
    "  - [ ] Comprendre comment il extrait les caractéristiques des images\n",
    "- [ ] Implémentation et visualisation avec Grad-CAM\n",
    "  - [ ] Voir quelles parties des images sont utilisées par le modèle pour faire ses prédictions\n",
    "- [ ] Discussion des erreurs courantes\n",
    "  - [ ] Confusion entre panneaux similaires\n",
    "  - [ ] Exploration de solutions potentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183fe5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b057e50",
   "metadata": {},
   "source": [
    "## 8. **Extension du Projet (Facultatif)**\n",
    "  - Poursuivre le projet (classification + localisation, tests dans des conditions adverses).\n",
    "  - Propositions pour des expériences plus avancées (détection d’objets, robustesse aux perturbations).\n",
    "\n",
    "## ToDo\n",
    "- [ ] Implémentation d’une architecture de détection d’objets\n",
    "- [ ] Ajout de bruit ou d’occlusions aux images pour tester la robustesse du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cea94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c86667",
   "metadata": {},
   "source": [
    "## 9. **Code Python, Rédaction du Rapport et Présentation**\n",
    "  - Résumé du projet.\n",
    "\n",
    "## ToDo\n",
    "- [ ] Code Python \n",
    "- [ ] Explication détaillée (Rapport 5-10 pages)\n",
    "- [ ] Explicaiton synthétique (Présentation 10 slides)\n",
    "- [ ] Sauvegarde du modèle entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa32e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d276598",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
